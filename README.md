# Plataforma As√≠ncrona para Flujos de Agentes de IA

Este proyecto es una plataforma backend robusta y escalable, dise√±ada para la **ejecuci√≥n as√≠ncrona de flujos complejos de agentes de IA** construidos con LangChain. Su arquitectura gen√©rica permite a los desarrolladores integrar y ejecutar f√°cilmente diferentes tareas de IA (desde simples generadores de texto hasta complejos agentes con herramientas como b√∫squeda web), mientras se ofrece **feedback en tiempo real al cliente** sobre el progreso de cada tarea.

## ‚ú® Caracter√≠sticas Principales

-   **Ejecuci√≥n As√≠ncrona**: Utiliza **Celery y Redis** para delegar tareas pesadas y de larga duraci√≥n a procesos en segundo plano (*workers*), asegurando que la aplicaci√≥n principal nunca se bloquee y pueda manejar m√∫ltiples peticiones simult√°neamente.
-   **Arquitectura Gen√©rica de Flujos**: El sistema no est√° atado a una tarea espec√≠fica. A trav√©s de un "Registro de Flujos", se pueden a√±adir nuevos agentes y cadenas de LangChain simplemente definiendo una funci√≥n y registr√°ndola, sin necesidad de modificar la l√≥gica central de ejecuci√≥n.
-   **Feedback en Tiempo Real**: Implementa **Server-Sent Events (SSE)** para establecer un canal de comunicaci√≥n unidireccional y persistente entre el servidor Django y el cliente. Esto permite enviar actualizaciones detalladas del estado y los resultados intermedios de cada paso del flujo a medida que ocurren.
-   **Escalabilidad y Aislamiento**: Toda la aplicaci√≥n est√° orquestada con **Docker Compose**, definiendo servicios separados para el servidor web (Django), los workers (Celery), el broker de mensajes (Redis) y la base de datos (PostgreSQL). Esto facilita el despliegue y la escalabilidad horizontal.
-   **Extensible**: Dise√±ado desde cero para ser f√°cil de extender. A√±adir un nuevo y complejo flujo de IA es tan simple como escribir la l√≥gica del flujo y registrarlo en el sistema.

## üèóÔ∏è Arquitectura del Sistema

El flujo de comunicaci√≥n y ejecuci√≥n sigue el siguiente patr√≥n:

```
                  +-------------------------+
                  |  Cliente (Navegador)    |
                  +-------------------------+
                          |      ^
      (1) Iniciar Tarea   |      | (4) Stream de Estado (SSE)
        (POST /start-task)|      |
                          v      |
                  +-------------------------+
                  |   Servidor Web (Django) |
                  +-------------------------+
                          |      ^
      (2) Enviar Tarea    |      | (3) Leer Estado de Tarea
        a la cola         |      |
                          v      |
                  +-------------------------+      +--------------------------+
                  |     Broker (Redis)      |<---->| Backend Resultados (Redis)|
                  +-------------------------+      +--------------------------+
                          |                                   ^
      (2.1) Worker        |                                   | (3.1) Actualizar
        recoge tarea      |                                   |     Progreso
                          v                                   |
                  +-------------------------+      +--------------------------+
                  |      Worker (Celery)    |----->|  Base de Datos (PostgreSQL)|
                  +-------------------------+      +--------------------------+
                          |                                (Opcional: persistir
  (2.2) Ejecuta flujo     |                                   resultados finales)
  de LangChain e interact√∫a
  con APIs externas (ej. Gemini)
```

1.  El **Cliente** env√≠a una petici√≥n POST a Django para iniciar un flujo espec√≠fico.
2.  **Django** crea una tarea en Celery y la env√≠a al broker **Redis**. Inmediatamente, devuelve un `task_id` al cliente.
3.  El **Worker de Celery** recoge la tarea, la ejecuta y actualiza su estado y resultados intermedios en el backend de resultados (tambi√©n Redis).
4.  El **Cliente**, al recibir el `task_id`, establece una conexi√≥n SSE con Django, que a su vez consulta el estado de la tarea en Redis y transmite las actualizaciones en tiempo real.

## üõ†Ô∏è Stack Tecnol√≥gico

-   **Backend**: Django
-   **Tareas As√≠ncronas**: Celery
-   **Broker de Mensajes y Cach√©**: Redis
-   **Base de Datos**: PostgreSQL
-   **Orquestaci√≥n de Contenedores**: Docker & Docker Compose
-   **Framework de IA**: LangChain
-   **Frontend**: HTML, CSS y JavaScript vainilla para la demostraci√≥n.

## üöÄ Puesta en Marcha

Sigue estos pasos para levantar el entorno de desarrollo local.

### Prerrequisitos

-   Tener [Docker](https://www.docker.com/get-started) y Docker Compose instalados.

### 1. Clonar el Repositorio

```bash
git clone https://github.com/carlosDAC2020/API-CTM.git
cd API-CTM
```

### 2. Configurar Variables de Entorno

Crea un archivo llamado `.env` en la ra√≠z del proyecto. Puedes copiar el archivo `env.example` (si existe) o usar la siguiente plantilla. Rellena tus claves de API.

```dotenv
# Clave secreta de Django (puedes generar una con python -c 'from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())')
SECRET_KEY=tu_secret_key_aqui

# Configuraci√≥n de la Base de Datos PostgreSQL
POSTGRES_DB=django_db
POSTGRES_USER=django_user
POSTGRES_PASSWORD=supersecretpassword
POSTGRES_HOST=db
POSTGRES_PORT=5432

# Claves de APIs para los flujos de LangChain
GEMINI_API_KEY=tu_api_key_de_gemini
TAVILY_API_KEY=tu_api_key_de_tavily
```

### 3. Construir y Levantar los Contenedores

Este comando construir√° las im√°genes de Docker para el backend y el worker, y levantar√° todos los servicios.

```bash
docker-compose up --build -d
```
*(Usa `-d` para ejecutar en segundo plano)*.

### 4. Ejecutar las Migraciones de la Base de Datos

Una vez que los contenedores est√©n en ejecuci√≥n, abre una nueva terminal y ejecuta las migraciones iniciales de Django para crear las tablas en la base de datos PostgreSQL.

```bash
docker-compose exec backend python manage.py migrate
```

### 5. Acceder a la Aplicaci√≥n

¬°Listo! Abre tu navegador y visita **`http://localhost:8000`**.

## üß© C√≥mo A√±adir Nuevos Flujos de IA

La arquitectura est√° dise√±ada para ser f√°cilmente extensible. Para a√±adir un nuevo flujo:

1.  **Define el Flujo**: Ve al archivo `main/tasks.py` y crea una nueva funci√≥n que construya y devuelva tu cadena de LangChain. Por ejemplo: `_create_mi_nuevo_flujo(llm)`.
2.  **Reg√≠stralo**: A√±ade la funci√≥n al diccionario `FLOW_REGISTRY` con un nombre √∫nico.
    ```python
    FLOW_REGISTRY = {
        "poem_flow": _create_poem_flow,
        "web_search_flow": _create_web_search_flow,
        "mi_nuevo_flujo": _create_mi_nuevo_flujo, # <-- Tu nuevo flujo
    }
    ```
3.  **Actualiza el Frontend (Opcional)**: A√±ade la nueva opci√≥n al selector en `index.html` para que los usuarios puedan ejecutarlo.

---