# Plataforma As√≠ncrona para Flujos de Agentes de IA

Este proyecto es una plataforma backend robusta y escalable, dise√±ada para la **ejecuci√≥n as√≠ncrona de flujos complejos de agentes de IA** construidos con LangChain. Su arquitectura gen√©rica permite a los desarrolladores integrar y ejecutar f√°cilmente diferentes tareas de IA (desde simples generadores de texto hasta complejos agentes con herramientas como b√∫squeda web), mientras se ofrece **feedback en tiempo real al cliente** sobre el progreso de cada tarea.

## ‚ú® Caracter√≠sticas Principales

-   **Ejecuci√≥n As√≠ncrona**: Utiliza **Celery y Redis** para delegar tareas pesadas y de larga duraci√≥n a procesos en segundo plano (*workers*), asegurando que la aplicaci√≥n principal nunca se bloquee y pueda manejar m√∫ltiples peticiones simult√°neamente.
-   **Arquitectura Gen√©rica de Flujos**: El sistema no est√° atado a una tarea espec√≠fica. A trav√©s de un "Registro de Flujos", se pueden a√±adir nuevos agentes y cadenas de LangChain simplemente definiendo una funci√≥n y registr√°ndola, sin necesidad de modificar la l√≥gica central de ejecuci√≥n.
-   **Feedback en Tiempo Real**: Implementa **Server-Sent Events (SSE)** para establecer un canal de comunicaci√≥n unidireccional y persistente entre el servidor Django y el cliente. Esto permite enviar actualizaciones detalladas del estado y los resultados intermedios de cada paso del flujo a medida que ocurren.
-   **Escalabilidad y Aislamiento**: Toda la aplicaci√≥n est√° orquestada con **Docker Compose**, definiendo servicios separados para el servidor web (Django), los workers (Celery), el broker de mensajes (Redis) y la base de datos (PostgreSQL). Esto facilita el despliegue y la escalabilidad horizontal.
-   **Extensible**: Dise√±ado desde cero para ser f√°cil de extender. A√±adir un nuevo y complejo flujo de IA es tan simple como escribir la l√≥gica del flujo y registrarlo en el sistema.

## üèóÔ∏è Arquitectura del Sistema

El flujo de comunicaci√≥n y ejecuci√≥n sigue el siguiente patr√≥n:

![Diagrama](/docs/diagrama%20de%20ejeucion.png)

1.  El **Cliente** env√≠a una petici√≥n POST a Django para iniciar un flujo espec√≠fico.
2.  **Django** crea una tarea en Celery y la env√≠a al broker **Redis**. Inmediatamente, devuelve un `task_id` al cliente.
3.  El **Worker de Celery** recoge la tarea, la ejecuta y actualiza su estado y resultados intermedios en el backend de resultados (tambi√©n Redis).
4.  El **Cliente**, al recibir el `task_id`, establece una conexi√≥n SSE con Django, que a su vez consulta el estado de la tarea en Redis y transmite las actualizaciones en tiempo real.

## üõ†Ô∏è Stack Tecnol√≥gico

-   **Backend**: Django
-   **Tareas As√≠ncronas**: Celery
-   **Broker de Mensajes y Cach√©**: Redis
-   **Base de Datos**: PostgreSQL
-   **Orquestaci√≥n de Contenedores**: Docker & Docker Compose
-   **Framework de IA**: LangChain
-   **Frontend**: HTML, CSS y JavaScript vainilla para la demostraci√≥n.

## üöÄ Puesta en Marcha

Sigue estos pasos para levantar el entorno de desarrollo local.

### Prerrequisitos

-   Tener [Docker](https://www.docker.com/get-started) y Docker Compose instalados.

### 1. Clonar el Repositorio

```bash
git clone https://github.com/carlosDAC2020/API-CTM.git
cd API-CTM
```

### 2. Configurar Variables de Entorno

Crea un archivo llamado `.env` en la ra√≠z del proyecto. Puedes copiar el archivo `env.example` (si existe) o usar la siguiente plantilla. Rellena tus claves de API.

```dotenv
# Clave secreta de Django (puedes generar una con python -c 'from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())')
SECRET_KEY=tu_secret_key_aqui

# Configuraci√≥n de la Base de Datos PostgreSQL
POSTGRES_DB=django_db
POSTGRES_USER=django_user
POSTGRES_PASSWORD=supersecretpassword
POSTGRES_HOST=db
POSTGRES_PORT=5432

# Claves de APIs para los flujos de LangChain
GEMINI_API_KEY=tu_api_key_de_gemini
TAVILY_API_KEY=tu_api_key_de_tavily
```

### 3. Construir y Levantar los Contenedores

Este comando construir√° las im√°genes de Docker para el backend y el worker, y levantar√° todos los servicios.

```bash
docker-compose up --build -d
```
*(Usa `-d` para ejecutar en segundo plano)*.

### 4. Ejecutar las Migraciones de la Base de Datos

Una vez que los contenedores est√©n en ejecuci√≥n, abre una nueva terminal y ejecuta las migraciones iniciales de Django para crear las tablas en la base de datos PostgreSQL.

```bash
docker-compose exec backend python manage.py migrate
```

### 5. Acceder a la Aplicaci√≥n

¬°Listo! Abre tu navegador y visita **`http://localhost:8000`**.

## üß© C√≥mo A√±adir Nuevos Flujos de IA

La arquitectura est√° dise√±ada para ser f√°cilmente extensible. Para a√±adir un nuevo flujo:

1.  **Define el Flujo**: Ve al archivo `main/tasks.py` y crea una nueva funci√≥n que construya y devuelva tu cadena de LangChain. Por ejemplo: `_create_mi_nuevo_flujo(llm)`.
2.  **Reg√≠stralo**: A√±ade la funci√≥n al diccionario `FLOW_REGISTRY` con un nombre √∫nico.
    ```python
    FLOW_REGISTRY = {
        "poem_flow": _create_poem_flow,
        "web_search_flow": _create_web_search_flow,
        "mi_nuevo_flujo": _create_mi_nuevo_flujo, # <-- Tu nuevo flujo
    }
    ```
3.  **Actualiza el Frontend (Opcional)**: A√±ade la nueva opci√≥n al selector en `index.html` para que los usuarios puedan ejecutarlo.


---

## üîå Gu√≠a de uso 

Esta secci√≥n documenta los endpoints de la API necesarios para interactuar con la plataforma de ejecuci√≥n de flujos.

La comunicaci√≥n se basa en dos endpoints principales: uno para iniciar una tarea y otro para recibir sus actualizaciones en tiempo real.

### Endpoint 1: Iniciar un Flujo de Trabajo

Este endpoint crea una nueva tarea as√≠ncrona y la pone en la cola para su ejecuci√≥n.

*   **URL**: `/start-task/`
*   **M√©todo**: `POST`
*   **Content-Type**: `application/json`
*   **Protecci√≥n CSRF**: S√≠. La petici√≥n debe incluir la cabecera `X-CSRFToken`.

#### Cuerpo de la Petici√≥n (Request Body)

El cuerpo de la petici√≥n es un objeto JSON que especifica qu√© flujo ejecutar y qu√© par√°metros proporcionarle.

```json
{
  "flow": "nombre_del_flujo",
  "inputs": {
    "parametro_1": "valor_1",
    "parametro_2": "valor_2"
  }
}
```

*   `flow` (string, **requerido**): El nombre identificador del flujo que se desea ejecutar.
*   `inputs` (objeto, **opcional**): Un objeto JSON que contiene los par√°metros necesarios para ese flujo espec√≠fico. Si un flujo no requiere inputs, se puede enviar un objeto vac√≠o `{}`.

#### Flujos Disponibles(ejemplos) y sus Inputs

| `nombre_del_flujo` | Descripci√≥n                                 | `inputs` Requeridos                                     |
|--------------------|---------------------------------------------|---------------------------------------------------------|
| `poem_flow`        | Genera un poema sobre un tema aleatorio.    | Objeto vac√≠o: `{}`                                      |
| `web_search_flow`  | Busca en la web y resume la respuesta.      | `{ "question": "Tu pregunta aqu√≠..." }`                 |
| *... (a√±adir m√°s flujos aqu√≠ a medida que se creen)* | | |


#### Respuesta Exitosa (C√≥digo 200 OK)

Si la tarea se crea correctamente, la API devolver√° un objeto JSON con el ID √∫nico de la tarea. Este ID es crucial para el siguiente paso.

```json
{
  "task_id": "a1b2c3d4-e5f6-7890-1234-567890abcdef"
}
```

#### Respuestas de Error

*   **C√≥digo 400 (Bad Request)**: El cuerpo de la petici√≥n es inv√°lido, no es un JSON, o falta el campo `flow`.
*   **C√≥digo 403 (Forbidden)**: Falta el token CSRF o es incorrecto.
*   **C√≥digo 500 (Internal Server Error)**: Ocurri√≥ un error inesperado al crear la tarea.

### Endpoint 2: Recibir Estado de la Tarea (Server-Sent Events)

Una vez que tienes el `task_id` del endpoint anterior, debes abrir una conexi√≥n de tipo Server-Sent Events (SSE) a este endpoint para recibir las actualizaciones en tiempo real.

*   **URL**: `/task-status/<task_id>/`
*   **M√©todo**: `GET`
*   **Content-Type**: `text/event-stream`

#### C√≥mo Consumirlo en JavaScript

Debes usar la clase `EventSource` para suscribirte a las actualizaciones.

```javascript
// Obt√©n el task_id de la respuesta del endpoint /start-task/
const taskId = 'a1b2c3d4-e5f6-7890-1234-567890abcdef';
const eventSource = new EventSource(`/task-status/${taskId}/`);

eventSource.onmessage = function(event) {
    // Parsea los datos JSON que llegan en cada evento
    const data = JSON.parse(event.data);
    console.log("Nueva actualizaci√≥n:", data);

    // Aqu√≠ va tu l√≥gica para actualizar la UI con la nueva informaci√≥n
    // updateTaskUI(taskId, data);

    // Si la tarea ha terminado, cierra la conexi√≥n para ahorrar recursos
    if (data.state === 'SUCCESS' || data.state === 'FAILURE') {
        eventSource.close();
    }
};

eventSource.onerror = function(error) {
    console.error("Error en la conexi√≥n SSE:", error);
    eventSource.close();
};
```

#### Formato de los Datos Recibidos

Cada mensaje recibido a trav√©s del `EventSource` ser√° un objeto JSON con la siguiente estructura:

```json
{
  "state": "ESTADO_ACTUAL",
  "details": { ... }
}
```

*   `state` (string): El estado general de la tarea. Puede ser:
    *   `PENDING`: La tarea est√° en la cola, esperando ser procesada.
    *   `PROGRESS`: La tarea est√° siendo ejecutada por un worker.
    *   `SUCCESS`: La tarea finaliz√≥ con √©xito.
    *   `FAILURE`: La tarea fall√≥.

*   `details` (objeto): Contiene la informaci√≥n detallada del estado `PROGRESS`, `SUCCESS` o `FAILURE`.

##### Estructura del objeto `details`

```json
{
    "status": "Mensaje de estado actual, ej: 'Ejecutando LLM...'",
    "progress": 80, // Un n√∫mero del 0 al 100
    "step_results": [
        // Una lista de los pasos completados hasta ahora
        {
            "type": "log",
            "message": "‚ñ∂Ô∏è Iniciando paso: 'Generando Prompt del Tema'..."
        },
        {
            "type": "tool_result",
            "step_name": "B√∫squeda en la Web (Tavily)",
            "tool": "tavily_search_results_json",
            "data": [
                {
                    "url": "https://example.com",
                    "content": "Contenido encontrado en la web..."
                }
            ]
        }
    ],
    "final_result": "El resultado final de la cadena cuando state es 'SUCCESS'"
}
```

*   `step_results` (array): Una lista ordenada de los eventos ocurridos durante la ejecuci√≥n. Cada objeto en el array tiene un `type` que te permite renderizarlo de forma diferente:
    *   `type: "log"`: Un simple mensaje de progreso. Muestra el `message`.
    *   `type: "tool_result"`: El resultado de la ejecuci√≥n de una herramienta. Muestra el `step_name` como t√≠tulo y el contenido de `data` (que suele ser un objeto o lista de objetos JSON).


### üì¨ M√≥dulo de Notificaciones As√≠ncronas

El proyecto incluye un m√≥dulo de notificaciones robusto y desacoplado, encapsulado en la aplicaci√≥n Django `notifications`. Su prop√≥sito es gestionar el env√≠o de correos electr√≥nicos de forma as√≠ncrona, asegurando que las operaciones de notificaci√≥n no afecten el rendimiento de la aplicaci√≥n principal ni la experiencia del usuario.

#### Arquitectura del Servicio de Notificaciones

Este servicio sigue una arquitectura basada en tareas en segundo plano, integr√°ndose perfectamente con el ecosistema de Celery y Redis ya establecido.